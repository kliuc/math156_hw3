{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11321669-b90e-4bc7-9270-de880cdf60d9",
   "metadata": {},
   "source": [
    "This notebook contains a sequence of `numpy` and calculus exercises, with the goal of implementing the cross entropy loss function and its gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66338983-d3d6-4b59-bb3c-d32c59a050d0",
   "metadata": {},
   "source": [
    "Suppose we have $n$ data points and $k$ classes, and let ${\\bf y}$ be the $k \\times n$ matrix consisting of ground truths. The cross entropy loss for some predictions ${\\bf p}$ is\n",
    "$$E({\\bf p}) = -{1 \\over n}\\sum_{i = 1}^n \\sum_{j = 1}^k y_{ij} \\ln p_{ij}.$$\n",
    "Here is a non-vectorized implementation of cross entropy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f8b4a14-5260-460a-bdfb-240b2153d57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def CE_nonvectorized(y, p):\n",
    "    \"\"\"A nonvectorized implementation of cross entropy.\n",
    "\n",
    "    Args:\n",
    "        y: Ground truths, shape (k, n).\n",
    "        p: Predictions, shape (k, n).\n",
    "\n",
    "    Returns:\n",
    "        (float) The cross entropy loss of p.\n",
    "    \"\"\"\n",
    "    return -(1 / y.shape[1]) * sum(\n",
    "        y[i, j] * math.log(p[i, j] + 1e-6) # add 1e-6 to allow for zeros and for stability\n",
    "        for i in range(y.shape[0])\n",
    "        for j in range(y.shape[1])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5406f54b-9334-42d4-abd2-87abbb92b1b3",
   "metadata": {},
   "source": [
    "### Exercise 1 (understanding check)\n",
    "Given the toy ground truths `y` below, find a `p_close` with entires in `{0.1, 0.2, ..., 0.9}` that minimizes the loss of `p_close`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d34a3bba-189d-49d9-9f35-29c7b7d97035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of p_constant: 1.0986092886726098\n",
      "loss of p_close: 0.10535940454733242\n"
     ]
    }
   ],
   "source": [
    "y = np.array([\n",
    "    [1, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 1],\n",
    "    [0, 1, 1, 0, 0]\n",
    "])\n",
    "p_init = np.array([\n",
    "    [1/3, 1/3, 1/3, 1/3, 1/3],\n",
    "    [1/3, 1/3, 1/3, 1/3, 1/3],\n",
    "    [1/3, 1/3, 1/3, 1/3, 1/3]\n",
    "])\n",
    "p_close = np.array([\n",
    "    [0.9, 0.0, 0.0, 0.1, 0.1],\n",
    "    [0.0, 0.1, 0.1, 0.9, 0.9],\n",
    "    [0.1, 0.9, 0.9, 0.0, 0.0]\n",
    "])\n",
    "\n",
    "print(f'loss of p_constant: {CE_nonvectorized(y, p_init)}')\n",
    "print(f'loss of p_close: {CE_nonvectorized(y, p_close)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76a10ff-6729-4a38-a3b4-e74b712e5704",
   "metadata": {},
   "source": [
    "### Exercise 2 (numpy)\n",
    "Implement the following check that the columns of `p_init` and `p_close` sum to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b9a32ff-d569-4fe9-8822-cf3446073f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_sum_to_1(A):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        A: A two-dimensional matrix.\n",
    "\n",
    "    Returns:\n",
    "        (True/False) Whether the columns of the input matrix sum to 1.\n",
    "    \"\"\"\n",
    "    return (np.sum(A, axis=0) == 1).all()\n",
    "\n",
    "assert columns_sum_to_1(p_init)\n",
    "assert columns_sum_to_1(p_close)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31970e5-6a68-4eea-a6ef-e0dd9dc06220",
   "metadata": {},
   "source": [
    "### Exercise 3 (calculus)\n",
    "To vectorize the implementation of cross entropy, express $E({\\bf p})$ using matrix operations, recalling the Hadamard product $\\odot$ and denoting by $\\text{sum}(A)$ the sum of the entires of a matrix $A$:\n",
    "$$E({\\bf p}) = -{1\\over n}(y \\odot \\log(p))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6a1b68-9fd1-4c5d-b342-bd809879c59f",
   "metadata": {},
   "source": [
    "### Exercise 4 (numpy)\n",
    "Now write a vectorized implementation of cross entropy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba730772-92ca-448f-a95b-f5f0440a5514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CE_vectorized(y, p):\n",
    "    \"\"\"A vectorized implementation of cross entropy.\n",
    "\n",
    "    Args:\n",
    "        y: Ground truths, shape (k, n).\n",
    "        p: Predictions, shape (k, n).\n",
    "\n",
    "    Returns:\n",
    "        (float) The cross entropy loss of p.\n",
    "    \"\"\"\n",
    "    return -np.sum(y * np.log(p + 1e-6)) / y.shape[1]\n",
    "\n",
    "assert CE_nonvectorized(y, p_init) == CE_vectorized(y, p_init)\n",
    "assert CE_nonvectorized(y, p_close) == CE_vectorized(y, p_close)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bf0a2a-6e1c-426d-bbd5-da4e35a480e2",
   "metadata": {},
   "source": [
    "Here is a speed comparison that shows that `CE_vectorized` is about 30 times faster than `CE_nonvectorized`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab3cd962-a183-4481-a412-8ba54192d3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 21.03it/s]\n",
      "100%|██████████| 20/20 [00:10<00:00,  1.91it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for _ in tqdm(range(20)):\n",
    "    CE_vectorized(np.random.rand(10, 60000), np.random.rand(10, 60000))\n",
    "\n",
    "for _ in tqdm(range(20)):\n",
    "    CE_nonvectorized(np.random.rand(10, 60000), np.random.rand(10, 60000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71af960a-1798-462a-bd9d-dac3e03d7fce",
   "metadata": {},
   "source": [
    "### Exercise 5 (calculus)\n",
    "Now compute the gradient of $E({\\bf p}),$ recalling the Hadamard division $\\oslash$:\n",
    "$$\\nabla E({\\bf p}) = -{1\\over n}(y \\oslash p)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e05cc29-89c9-4681-b2f1-35222fd1d5d4",
   "metadata": {},
   "source": [
    "### Exercise 6 (numpy)\n",
    "Finally, write a vectorized implementation of the gradient of cross entropy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "322cfa95-e07e-4970-a0b6-43c00ded5693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CE_gradient_vectorized(y, p):\n",
    "    \"\"\"A vectorized implementation of the gradient of cross entropy.\n",
    "\n",
    "    Args:\n",
    "        y: Ground truths, shape (k, n).\n",
    "        p: Predictions, shape (k, n).\n",
    "\n",
    "    Returns:\n",
    "        The gradient of cross entropy, shape (k, n).\n",
    "    \"\"\"\n",
    "    return -(y / (p + 1e-6)) / y.shape[1]\n",
    "\n",
    "assert np.isclose(CE_gradient_vectorized(y, p_init), np.array([\n",
    "    [-0.6,    0,    0,    0,    0],\n",
    "    [   0,    0,    0, -0.6, -0.6],\n",
    "    [   0, -0.6, -0.6,    0,    0],\n",
    "])).all()\n",
    "\n",
    "assert np.isclose(CE_gradient_vectorized(y, p_close), np.array([\n",
    "    [-2/9,    0,    0,    0,    0],\n",
    "    [   0,    0,    0, -2/9, -2/9],\n",
    "    [   0, -2/9, -2/9,    0,    0],\n",
    "])).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec206dd1-8eb6-4994-b74b-92ebf21acbd5",
   "metadata": {},
   "source": [
    "### Exercise 7 (understanding)\n",
    "What is the relationship between the locations of the nonzero gradient entries and the ground-truths? Explain the following slogan: \"cross entropy uses the carrot, whereas MSE uses the stick.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c93bebe-33af-4077-97ef-043271c97ea4",
   "metadata": {},
   "source": [
    "You can now copy-paste `CE_gradient_vectorized` and `CE_vectorized` (transpose the answer first) into `losses.py` for HW 3 Problem 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
